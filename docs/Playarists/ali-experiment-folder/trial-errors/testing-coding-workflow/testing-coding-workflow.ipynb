{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import os\\nimport pandas as pd\\n\\n# Read ERIH-PLUS approved journals dataset\\nerih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv')\\n\\n# Get the list of CSV files in the OpenCitations Meta data dump directory\\ncsv_directory = 'path/to/csv/files'\\ncsv_files = [f for f in os.listdir(csv_directory) if f.endswith('.csv')]\\n\\n# Initialize an empty dataframe for the mapping of OpenCitations Meta and ERIH-PLUS venue data\\nmapping_df = pd.DataFrame(columns=['oc_omid', 'oc_issn', 'ep_id', 'ep_issn'])\\n\\n# Iterate over the CSV files\\nfor csv_file in csv_files:\\n    # Read OpenCitations Meta data dump in chunks\\n    chunksize = 10 ** 5\\n    meta_data_chunks = pd.read_csv(os.path.join(csv_directory, csv_file), chunksize=chunksize, iterator=True)\\n\\n    # Iterate over the chunks of OpenCitations Meta data dump\\n    for chunk in meta_data_chunks:\\n        # Filter the chunk to include only venue information\\n        venue_chunk = chunk[chunk['type'] == 'venue']\\n\\n        # Merge the ERIH-PLUS and OpenCitations Meta data on ISSN\\n        merged_chunk = erih_plus_df.merge(venue_chunk, left_on=['print issn', 'online issn'], right_on=['issn'], how='inner')\\n\\n        # Keep only the relevant columns for the mapping dataframe\\n        merged_chunk = merged_chunk[['oc_omid', 'oc_issn', 'journal id', 'issn']].rename(columns={'journal id': 'ep_id', 'issn': 'ep_issn'})\\n\\n        # Append the merged chunk to the mapping dataframe\\n        mapping_df = mapping_df.append(merged_chunk, ignore_index=True)\\n\\n# Save the mapping dataframe as a CSV file\\nmapping_df.to_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv', index=False) \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read ERIH-PLUS approved journals dataset\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv')\n",
    "\n",
    "# Get the list of CSV files in the OpenCitations Meta data dump directory\n",
    "csv_directory = 'path/to/csv/files'\n",
    "csv_files = [f for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty dataframe for the mapping of OpenCitations Meta and ERIH-PLUS venue data\n",
    "mapping_df = pd.DataFrame(columns=['oc_omid', 'oc_issn', 'ep_id', 'ep_issn'])\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for csv_file in csv_files:\n",
    "    # Read OpenCitations Meta data dump in chunks\n",
    "    chunksize = 10 ** 5\n",
    "    meta_data_chunks = pd.read_csv(os.path.join(csv_directory, csv_file), chunksize=chunksize, iterator=True)\n",
    "\n",
    "    # Iterate over the chunks of OpenCitations Meta data dump\n",
    "    for chunk in meta_data_chunks:\n",
    "        # Filter the chunk to include only venue information\n",
    "        venue_chunk = chunk[chunk['type'] == 'venue']\n",
    "\n",
    "        # Merge the ERIH-PLUS and OpenCitations Meta data on ISSN\n",
    "        merged_chunk = erih_plus_df.merge(venue_chunk, left_on=['print issn', 'online issn'], right_on=['issn'], how='inner')\n",
    "\n",
    "        # Keep only the relevant columns for the mapping dataframe\n",
    "        merged_chunk = merged_chunk[['oc_omid', 'oc_issn', 'journal id', 'issn']].rename(columns={'journal id': 'ep_id', 'issn': 'ep_issn'})\n",
    "\n",
    "        # Append the merged chunk to the mapping dataframe\n",
    "        mapping_df = mapping_df.append(merged_chunk, ignore_index=True)\n",
    "\n",
    "# Save the mapping dataframe as a CSV file\n",
    "mapping_df.to_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv', index=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11128 entries, 0 to 11127\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Journal ID              11128 non-null  int64 \n",
      " 1   Print ISSN              8774 non-null   object\n",
      " 2   Online ISSN             9570 non-null   object\n",
      " 3   Original Title          11128 non-null  object\n",
      " 4   International Title     11128 non-null  object\n",
      " 5   Country of Publication  11007 non-null  object\n",
      " 6   ERIH PLUS Disciplines   11128 non-null  object\n",
      " 7   OECD Classifications    11128 non-null  object\n",
      " 8   [Last Updated]          11128 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 782.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n",
    "erih_plus_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Journal ID', 'Print ISSN', 'Online ISSN', 'Original Title',\n",
      "       'International Title', 'Country of Publication',\n",
      "       'ERIH PLUS Disciplines', 'OECD Classifications', '[Last Updated]'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(erih_plus_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal ID</th>\n",
       "      <th>Print ISSN</th>\n",
       "      <th>Online ISSN</th>\n",
       "      <th>Original Title</th>\n",
       "      <th>International Title</th>\n",
       "      <th>Country of Publication</th>\n",
       "      <th>ERIH PLUS Disciplines</th>\n",
       "      <th>OECD Classifications</th>\n",
       "      <th>[Last Updated]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>486254</td>\n",
       "      <td>1989-3477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@tic.revista d'innovació educativa</td>\n",
       "      <td>@tic.revista d'innovació educativa</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Interdisciplinary research in the Social Scien...</td>\n",
       "      <td>Educational Sciences; Other Social Sciences</td>\n",
       "      <td>2015-06-25 13:48:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Journal ID Print ISSN Online ISSN                      Original Title  \\\n",
       "0      486254  1989-3477         NaN  @tic.revista d'innovació educativa   \n",
       "\n",
       "                  International Title Country of Publication  \\\n",
       "0  @tic.revista d'innovació educativa                  Spain   \n",
       "\n",
       "                               ERIH PLUS Disciplines  \\\n",
       "0  Interdisciplinary research in the Social Scien...   \n",
       "\n",
       "                          OECD Classifications       [Last Updated]  \n",
       "0  Educational Sciences; Other Social Sciences  2015-06-25 13:48:26  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erih_plus_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3997 entries, 0 to 3996\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         3997 non-null   object \n",
      " 1   title      3981 non-null   object \n",
      " 2   author     3864 non-null   object \n",
      " 3   issue      53 non-null     object \n",
      " 4   volume     53 non-null     float64\n",
      " 5   venue      2146 non-null   object \n",
      " 6   page       66 non-null     object \n",
      " 7   pub_date   3919 non-null   object \n",
      " 8   type       3990 non-null   object \n",
      " 9   publisher  3924 non-null   object \n",
      " 10  editor     1938 non-null   object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 343.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read 0.csv from meta dataset\n",
    "ereading_one_csv = pd.read_csv('0.csv')\n",
    "ereading_one_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>issue</th>\n",
       "      <th>volume</th>\n",
       "      <th>venue</th>\n",
       "      <th>page</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>editor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta:br/060209 doi:10.4230/lipics.approx/rando...</td>\n",
       "      <td>Distributed Testing Of Graph Isomorphism In Th...</td>\n",
       "      <td>Levi, Reut [meta:ra/0610110096 orcid:0000-0003...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[meta:br/060182 issn:1868-8969]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>report</td>\n",
       "      <td>Schloss Dagstuhl - Leibniz-Zentrum Für Informa...</td>\n",
       "      <td>Byrka, Jarosław [meta:ra/069044096 orcid:0000-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  meta:br/060209 doi:10.4230/lipics.approx/rando...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distributed Testing Of Graph Isomorphism In Th...   \n",
       "\n",
       "                                              author issue  volume  \\\n",
       "0  Levi, Reut [meta:ra/0610110096 orcid:0000-0003...   NaN     NaN   \n",
       "\n",
       "                             venue page pub_date    type  \\\n",
       "0  [meta:br/060182 issn:1868-8969]  NaN     2020  report   \n",
       "\n",
       "                                           publisher  \\\n",
       "0  Schloss Dagstuhl - Leibniz-Zentrum Für Informa...   \n",
       "\n",
       "                                              editor  \n",
       "0  Byrka, Jarosław [meta:ra/069044096 orcid:0000-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ereading_one_csv.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[meta:br/060182 issn:1868-8969]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ereading_one_csv.venue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'issue', 'volume', 'venue', 'page', 'pub_date',\n",
      "       'type', 'publisher', 'editor'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'issn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\GitHub\\open-sci\\2022-2023\\docs\\Playarists\\ali-experiment-folder\\trial-errors\\testing-coding-workflow\\testing-coding-workflow.ipynb Cell 4\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(venue_data\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Merge the ERIH-PLUS and OpenCitations Meta data on ISSN\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#merged_data = erih_plus_df.merge(venue_data, left_on=['print issn', 'online issn'], right_on=['issn'], how='inner')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Merge the ERIH-PLUS and OpenCitations Meta data on print ISSN\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m merged_data_print \u001b[39m=\u001b[39m erih_plus_df\u001b[39m.\u001b[39;49mmerge(venue_data, left_on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPrint ISSN\u001b[39;49m\u001b[39m'\u001b[39;49m, right_on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39missn\u001b[39;49m\u001b[39m'\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Merge the ERIH-PLUS and OpenCitations Meta data on online ISSN\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m merged_data_online \u001b[39m=\u001b[39m erih_plus_df\u001b[39m.\u001b[39mmerge(venue_data, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOnline ISSN\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39missn\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\frame.py:10080\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10061\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m  10062\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m  10063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10076\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m  10077\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m  10078\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[1;32m> 10080\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m  10081\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m  10082\u001b[0m         right,\n\u001b[0;32m  10083\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m  10084\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m  10085\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m  10086\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m  10087\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m  10088\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m  10089\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m  10090\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m  10091\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m  10092\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m  10093\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m  10094\u001b[0m     )\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[39m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m rk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39;49m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'issn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n",
    "\n",
    "# Read ERIH-PLUS approved journals dataset\n",
    "#erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv')\n",
    "\n",
    "# Get the list of CSV files in the OpenCitations Meta data dump directory\n",
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\solo_one'\n",
    "\n",
    "csv_files = [f for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty dataframe for the mapping of OpenCitations Meta and ERIH-PLUS venue data\n",
    "mapping_df = pd.DataFrame(columns=['oc_omid', 'oc_issn', 'ep_id', 'ep_issn'])\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for csv_file in csv_files:\n",
    "    # Read OpenCitations Meta data dump\n",
    "    meta_data = pd.read_csv(os.path.join(csv_directory, csv_file))\n",
    "\n",
    "    # Filter the data to include only venue information\n",
    "    venue_data = meta_data[meta_data['type'] == 'venue']\n",
    "    print(venue_data.columns)\n",
    "\n",
    "    # Merge the ERIH-PLUS and OpenCitations Meta data on ISSN\n",
    "    #merged_data = erih_plus_df.merge(venue_data, left_on=['print issn', 'online issn'], right_on=['issn'], how='inner')\n",
    "\n",
    "    # Keep only the relevant columns for the mapping dataframe\n",
    "    #merged_data = merged_data[['oc_omid', 'oc_issn', 'journal id', 'issn']].rename(columns={'journal id': 'ep_id', 'issn': 'ep_issn'})\n",
    "    \n",
    "    # Merge the ERIH-PLUS and OpenCitations Meta data on print ISSN\n",
    "    merged_data_print = erih_plus_df.merge(venue_data, left_on='Print ISSN', right_on='issn', how='inner')\n",
    "\n",
    "    # Merge the ERIH-PLUS and OpenCitations Meta data on online ISSN\n",
    "    merged_data_online = erih_plus_df.merge(venue_data, left_on='Online ISSN', right_on='issn', how='inner')\n",
    "\n",
    "    # Concatenate the results\n",
    "    merged_data = pd.concat([merged_data_print, merged_data_online], ignore_index=True)\n",
    "\n",
    "    # Keep only the relevant columns for the mapping dataframe\n",
    "    merged_data = merged_data[['oc_omid', 'oc_issn', 'Journal ID', 'issn']].rename(columns={'Journal ID': 'ep_id', 'issn': 'ep_issn'})\n",
    "\n",
    "\n",
    "    # Append the merged data to the mapping dataframe\n",
    "    mapping_df = mapping_df.append(merged_data, ignore_index=True)\n",
    "\n",
    "# Save the mapping dataframe as a CSV file\n",
    "mapping_df.to_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the DOAJ dump CSV file\n",
    "doaj_df = pd.read_csv('doaj_dump.csv')\n",
    "\n",
    "# Create a dictionary of Open Access ISSNs\n",
    "oa_issn_dict = {}\n",
    "for _, row in doaj_df.iterrows():\n",
    "    for issn_type in ['Print ISSN', 'Online ISSN']:\n",
    "        issn = row[issn_type]\n",
    "        if not pd.isna(issn):\n",
    "            oa_issn_dict[issn] = True\n",
    "\n",
    "# Read the mapping dataframe\n",
    "mapping_df = pd.read_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv')\n",
    "\n",
    "# Merge Open Access information with the main dataframe\n",
    "mapping_df['Open Access'] = mapping_df['ep_issn'].map(oa_issn_dict)\n",
    "\n",
    "# Fill missing values in the 'Open Access' column with 'Unknown'\n",
    "mapping_df['Open Access'] = mapping_df['Open Access'].fillna('Unknown')\n",
    "\n",
    "# Save the updated dataframe as a CSV file\n",
    "mapping_df.to_csv('OpenCitations_Meta_ERIH_PLUS_OA_mapping.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11128 entries, 0 to 11127\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Journal ID              11128 non-null  int64 \n",
      " 1   Print ISSN              8774 non-null   object\n",
      " 2   Online ISSN             9570 non-null   object\n",
      " 3   Original Title          11128 non-null  object\n",
      " 4   International Title     11128 non-null  object\n",
      " 5   Country of Publication  11007 non-null  object\n",
      " 6   ERIH PLUS Disciplines   11128 non-null  object\n",
      " 7   OECD Classifications    11128 non-null  object\n",
      " 8   [Last Updated]          11128 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 782.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n",
    "erih_plus_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_meta_csv(file_path, erih_plus_df):\n",
    "    meta_data = pd.read_csv(file_path)\n",
    "    meta_data['issn'] = meta_data['venue'].str.extract(r'issn:(\\d{4}-\\d{3}[\\dX])')\n",
    "    \n",
    "    merged_data_print = erih_plus_df.merge(meta_data, left_on='Print ISSN', right_on='issn', how='inner')\n",
    "    merged_data_online = erih_plus_df.merge(meta_data, left_on='Online ISSN', right_on='issn', how='inner')\n",
    "    merged_data = pd.concat([merged_data_print, merged_data_online], ignore_index=True)\n",
    "    \n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligh\\AppData\\Local\\Temp\\ipykernel_16468\\1179333656.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(merged_data_file, ignore_index=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\GitHub\\open-sci\\2022-2023\\docs\\Playarists\\ali-experiment-folder\\trial-errors\\testing-coding-workflow\\testing-coding-workflow.ipynb Cell 14\u001b[0m in \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m file_name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(csv_directory, file_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     merged_data_file \u001b[39m=\u001b[39m process_meta_csv(file_path, erih_plus_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     merged_data \u001b[39m=\u001b[39m merged_data\u001b[39m.\u001b[39mappend(merged_data_file, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32me:\\GitHub\\open-sci\\2022-2023\\docs\\Playarists\\ali-experiment-folder\\trial-errors\\testing-coding-workflow\\testing-coding-workflow.ipynb Cell 14\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_meta_csv\u001b[39m(file_path, erih_plus_df):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     meta_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     meta_data[\u001b[39m'\u001b[39m\u001b[39missn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m meta_data[\u001b[39m'\u001b[39;49m\u001b[39mvenue\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mextract(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39missn:(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m{4}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m{3}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdX])\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     merged_data_print \u001b[39m=\u001b[39m erih_plus_df\u001b[39m.\u001b[39mmerge(meta_data, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPrint ISSN\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39missn\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/open-sci/2022-2023/docs/Playarists/ali-experiment-folder/trial-errors/testing-coding-workflow/testing-coding-workflow.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     merged_data_online \u001b[39m=\u001b[39m erih_plus_df\u001b[39m.\u001b[39mmerge(meta_data, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOnline ISSN\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39missn\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[0;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32me:\\data-science-project\\bert_py38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    232\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dumps'\n",
    "\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(csv_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, file_name)\n",
    "        merged_data_file = process_meta_csv(file_path, erih_plus_df)\n",
    "        merged_data = merged_data.append(merged_data_file, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_meta_csv(file_path, erih_plus_df):\n",
    "    meta_data = pd.read_csv(file_path)\n",
    "    meta_data['venue'] = meta_data['venue'].astype(str)\n",
    "    meta_data['issn'] = meta_data['venue'].str.extract(r'issn:(\\d{4}-\\d{3}[\\dX])')\n",
    "    \n",
    "    merged_data_print = erih_plus_df.merge(meta_data, left_on='Print ISSN', right_on='issn', how='inner')\n",
    "    merged_data_online = erih_plus_df.merge(meta_data, left_on='Online ISSN', right_on='issn', how='inner')\n",
    "    merged_data = pd.concat([merged_data_print, merged_data_online], ignore_index=True)\n",
    "    \n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\solo_one'\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(csv_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, file_name)\n",
    "        merged_data_file = process_meta_csv(file_path, erih_plus_df)\n",
    "        merged_data = pd.concat([merged_data, merged_data_file], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligh\\AppData\\Local\\Temp\\ipykernel_11260\\2117464585.py:1: DtypeWarning: Columns (1,2,15,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  read_merged_csv = pd.read_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal ID</th>\n",
       "      <th>Print ISSN</th>\n",
       "      <th>Online ISSN</th>\n",
       "      <th>Original Title</th>\n",
       "      <th>International Title</th>\n",
       "      <th>Country of Publication</th>\n",
       "      <th>ERIH PLUS Disciplines</th>\n",
       "      <th>OECD Classifications</th>\n",
       "      <th>[Last Updated]</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>issue</th>\n",
       "      <th>volume</th>\n",
       "      <th>venue</th>\n",
       "      <th>page</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>editor</th>\n",
       "      <th>issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341-0515</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Art and Art History, Cultural Studies, Human G...</td>\n",
       "      <td>Arts (Arts, History of Arts, Performing Arts, ...</td>\n",
       "      <td>2016-04-18 17:34:55</td>\n",
       "      <td>meta:br/060100 isbn:9780203417447 isbn:9780203...</td>\n",
       "      <td>...</td>\n",
       "      <td>Wulker, Nikolaus [meta:ra/0604250]; Mansat, Mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-10-12</td>\n",
       "      <td>reference book</td>\n",
       "      <td>Informa Uk Limited [meta:ra/0610116005 crossre...</td>\n",
       "      <td>Wülker, Nikolaus [meta:ra/0604253]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341-0515</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Art and Art History, Cultural Studies, Human G...</td>\n",
       "      <td>Arts (Arts, History of Arts, Performing Arts, ...</td>\n",
       "      <td>2016-04-18 17:34:55</td>\n",
       "      <td>meta:br/060176 issn:2747-4607 issn:2747-4623</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>488561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341-0515</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Art and Art History, Cultural Studies, Human G...</td>\n",
       "      <td>Arts (Arts, History of Arts, Performing Arts, ...</td>\n",
       "      <td>2016-04-18 17:34:55</td>\n",
       "      <td>meta:br/06084 doi:10.1201/b12413 doi:10.4324/9...</td>\n",
       "      <td>...</td>\n",
       "      <td>Webb, Ralph L. [meta:ra/0603398]; Kim, Nae-Hyu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-12-15</td>\n",
       "      <td>reference book</td>\n",
       "      <td>Informa Uk Limited [meta:ra/0610116005 crossre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341-0515</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Art and Art History, Cultural Studies, Human G...</td>\n",
       "      <td>Arts (Arts, History of Arts, Performing Arts, ...</td>\n",
       "      <td>2016-04-18 17:34:55</td>\n",
       "      <td>meta:br/060104 doi:10.4324/9780203477540 isbn:...</td>\n",
       "      <td>...</td>\n",
       "      <td>Helmer, Richard [meta:ra/0604277]; Hespanhol, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>reference book</td>\n",
       "      <td>Informa Uk Limited [meta:ra/0610116005 crossre...</td>\n",
       "      <td>Helmer, Richard [meta:ra/0604279]; Hespanhol, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341-0515</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>[i2] Investigación e Innovación en Arquitectur...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Art and Art History, Cultural Studies, Human G...</td>\n",
       "      <td>Arts (Arts, History of Arts, Performing Arts, ...</td>\n",
       "      <td>2016-04-18 17:34:55</td>\n",
       "      <td>meta:br/06046 doi:10.15405/epsbs(2357-1330).20...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>series</td>\n",
       "      <td>Cognitive-crcs [meta:ra/0640115479 crossref:6078]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Journal ID Print ISSN Online ISSN  \\\n",
       "0      488561        NaN   2341-0515   \n",
       "1      488561        NaN   2341-0515   \n",
       "2      488561        NaN   2341-0515   \n",
       "3      488561        NaN   2341-0515   \n",
       "4      488561        NaN   2341-0515   \n",
       "\n",
       "                                      Original Title  \\\n",
       "0  [i2] Investigación e Innovación en Arquitectur...   \n",
       "1  [i2] Investigación e Innovación en Arquitectur...   \n",
       "2  [i2] Investigación e Innovación en Arquitectur...   \n",
       "3  [i2] Investigación e Innovación en Arquitectur...   \n",
       "4  [i2] Investigación e Innovación en Arquitectur...   \n",
       "\n",
       "                                 International Title Country of Publication  \\\n",
       "0  [i2] Investigación e Innovación en Arquitectur...                  Spain   \n",
       "1  [i2] Investigación e Innovación en Arquitectur...                  Spain   \n",
       "2  [i2] Investigación e Innovación en Arquitectur...                  Spain   \n",
       "3  [i2] Investigación e Innovación en Arquitectur...                  Spain   \n",
       "4  [i2] Investigación e Innovación en Arquitectur...                  Spain   \n",
       "\n",
       "                               ERIH PLUS Disciplines  \\\n",
       "0  Art and Art History, Cultural Studies, Human G...   \n",
       "1  Art and Art History, Cultural Studies, Human G...   \n",
       "2  Art and Art History, Cultural Studies, Human G...   \n",
       "3  Art and Art History, Cultural Studies, Human G...   \n",
       "4  Art and Art History, Cultural Studies, Human G...   \n",
       "\n",
       "                                OECD Classifications       [Last Updated]  \\\n",
       "0  Arts (Arts, History of Arts, Performing Arts, ...  2016-04-18 17:34:55   \n",
       "1  Arts (Arts, History of Arts, Performing Arts, ...  2016-04-18 17:34:55   \n",
       "2  Arts (Arts, History of Arts, Performing Arts, ...  2016-04-18 17:34:55   \n",
       "3  Arts (Arts, History of Arts, Performing Arts, ...  2016-04-18 17:34:55   \n",
       "4  Arts (Arts, History of Arts, Performing Arts, ...  2016-04-18 17:34:55   \n",
       "\n",
       "                                                  id  ...  \\\n",
       "0  meta:br/060100 isbn:9780203417447 isbn:9780203...  ...   \n",
       "1       meta:br/060176 issn:2747-4607 issn:2747-4623  ...   \n",
       "2  meta:br/06084 doi:10.1201/b12413 doi:10.4324/9...  ...   \n",
       "3  meta:br/060104 doi:10.4324/9780203477540 isbn:...  ...   \n",
       "4  meta:br/06046 doi:10.15405/epsbs(2357-1330).20...  ...   \n",
       "\n",
       "                                              author issue  volume  venue  \\\n",
       "0  Wulker, Nikolaus [meta:ra/0604250]; Mansat, Mi...   NaN     NaN    NaN   \n",
       "1                                                NaN   NaN     NaN    NaN   \n",
       "2  Webb, Ralph L. [meta:ra/0603398]; Kim, Nae-Hyu...   NaN     NaN    NaN   \n",
       "3  Helmer, Richard [meta:ra/0604277]; Hespanhol, ...   NaN     NaN    NaN   \n",
       "4                                                NaN   NaN     NaN    NaN   \n",
       "\n",
       "  page    pub_date            type  \\\n",
       "0  NaN  2000-10-12  reference book   \n",
       "1  NaN         NaN     book series   \n",
       "2  NaN  2004-12-15  reference book   \n",
       "3  NaN  2017-10-02  reference book   \n",
       "4  NaN         NaN          series   \n",
       "\n",
       "                                           publisher  \\\n",
       "0  Informa Uk Limited [meta:ra/0610116005 crossre...   \n",
       "1                                                NaN   \n",
       "2  Informa Uk Limited [meta:ra/0610116005 crossre...   \n",
       "3  Informa Uk Limited [meta:ra/0610116005 crossre...   \n",
       "4  Cognitive-crcs [meta:ra/0640115479 crossref:6078]   \n",
       "\n",
       "                                              editor issn  \n",
       "0                 Wülker, Nikolaus [meta:ra/0604253]  NaN  \n",
       "1                                                NaN  NaN  \n",
       "2                                                NaN  NaN  \n",
       "3  Helmer, Richard [meta:ra/0604279]; Hespanhol, ...  NaN  \n",
       "4                                                NaN  NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_merged_csv = pd.read_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv')\n",
    "read_merged_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in e:\\data-science-project\\bert_py38\\lib\\site-packages (4.64.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'E:\\data-science-project\\bert_py38\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: colorama in e:\\data-science-project\\bert_py38\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_meta_csv_wrapper(args):\n",
    "    return process_meta_csv(*args)\n",
    "\n",
    "csv_directory = 'path/to/OpenCitations_Meta_CSV_files'\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_meta_csv_wrapper, [(file, erih_plus_df) for file in csv_files]), total=len(csv_files)))\n",
    "\n",
    "merged_data = pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('OpenCitations_Meta_ERIH_PLUS_mapping.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
