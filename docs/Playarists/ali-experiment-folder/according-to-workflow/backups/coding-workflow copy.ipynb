{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_meta_csv(chunk, erih_plus_df):\n",
    "    meta_data = chunk\n",
    "    meta_data['venue'] = meta_data['venue'].astype(str)\n",
    "    meta_data['issn'] = meta_data['venue'].str.extract(r'issn:(\\d{4}-\\d{3}[\\dX])')\n",
    "    \n",
    "    # Extract the identifier (OMID) from the 'id' column\n",
    "    meta_data['id'] = meta_data['id'].str.extract(r'(meta:[^ ]*)')\n",
    "    \n",
    "    merged_data_print = erih_plus_df.merge(meta_data, left_on='Print ISSN', right_on='issn', how='inner')\n",
    "    merged_data_online = erih_plus_df.merge(meta_data, left_on='Online ISSN', right_on='issn', how='inner')\n",
    "    merged_data = pd.concat([merged_data_print, merged_data_online], ignore_index=True)\n",
    "    \n",
    "    # Keep only the relevant columns for the mapping dataframe\n",
    "    merged_data = merged_data[['id', 'issn', 'Journal ID', 'Print ISSN', 'Online ISSN']].rename(columns={'id': 'OC_OMID', 'issn': 'OC_ISSN', 'Journal ID': 'EP_ID', 'Print ISSN': 'EP_Print_ISSN', 'Online ISSN': 'EP_Online_ISSN'})\n",
    "    \n",
    "    # Create the 'EP_ISSN' column\n",
    "    merged_data['EP_ISSN'] = merged_data['EP_Print_ISSN'].combine_first(merged_data['EP_Online_ISSN'])\n",
    "    \n",
    "    # Drop the 'EP_Print_ISSN' and 'EP_Online_ISSN' columns\n",
    "    merged_data = merged_data.drop(columns=['EP_Print_ISSN', 'EP_Online_ISSN'])\n",
    "    \n",
    "    # Drop rows with NaN values in the 'OC_ISSN' column\n",
    "    merged_data = merged_data.dropna(subset=['OC_ISSN']).reset_index(drop=True)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_file(input_file, erih_plus_df):\n",
    "    chunksize = 5 * 10 ** 3\n",
    "    processed_chunks = []\n",
    "    \n",
    "    # Read the input_file in chunks and process each chunk\n",
    "    with pd.read_csv(input_file, chunksize=chunksize) as reader:\n",
    "        for chunk in reader:\n",
    "            processed_chunk = process_meta_csv(chunk, erih_plus_df)\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "    # Combine the processed chunks into a single DataFrame\n",
    "    return pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "input_directory = \"I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump\"\n",
    "files = glob.glob(os.path.join(input_directory, \"*.csv\"))\n",
    "\n",
    "# Number of files to process at once\n",
    "batch_size = 100\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Initialize a progress bar to visualize the progress of processing batches of files\n",
    "with tqdm(total=len(files), desc=\"Batches\") as pbar:\n",
    "    # Process files in batches\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        # Get the current batch of files\n",
    "        batch_files = files[i:i + batch_size]\n",
    "\n",
    "        # Process the current batch of files using a ProcessPoolExecutor for parallelism\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            results = executor.map(process_file, batch_files, [erih_plus_df] * len(batch_files))\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        # Update the progress bar for each batch\n",
    "        pbar.update(len(batch_files))\n",
    "\n",
    "# Combine the results from all batches into a single DataFrame\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve OpenCitation Meta publication and Journals that are registered in ERIH-PLUS index\n",
    "\n",
    "Starting from the ERIH-PLUS index of Social Science and Humanities approved journals dataset \n",
    "ERIHPLUSapprovedJournals.csv\n",
    " (downloaded 27/04/2023) we want to retrieve all the publications belonging to one of those journals, included in OpenCitations Meta database (https://opencitations.net/meta#:~:text=For%20each%20publication%2C%20the%20metadata,and%20PubMed%20Identifiers%20(PMIDs).)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 \n",
    "\n",
    "In order to fulfill this task, we intend to download the data dump and perform chunk operations (either reading the csv with pandas setting a chunksize parameter, using os library to iterate over the folder's files, reading directly the zip file using gzip library etc.)\n",
    "Note that the OpenCitations Meta data dump has a row for each entity that is either a publication or a venue. At this moment we don't need publication information, so we would need to cut down the dataset to only have venues information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    return dialect.delimiter\n",
    "\n",
    "delimiter = detect_delimiter('ERIHPLUSapprovedJournals.csv')\n",
    "erih_plus_df = pd.read_csv('ERIHPLUSapprovedJournals.csv', sep=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal ID</th>\n",
       "      <th>Print ISSN</th>\n",
       "      <th>Online ISSN</th>\n",
       "      <th>Original Title</th>\n",
       "      <th>International Title</th>\n",
       "      <th>Country of Publication</th>\n",
       "      <th>ERIH PLUS Disciplines</th>\n",
       "      <th>OECD Classifications</th>\n",
       "      <th>[Last Updated]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>486254</td>\n",
       "      <td>1989-3477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@tic.revista d'innovació educativa</td>\n",
       "      <td>@tic.revista d'innovació educativa</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Interdisciplinary research in the Social Scien...</td>\n",
       "      <td>Educational Sciences; Other Social Sciences</td>\n",
       "      <td>2015-06-25 13:48:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Journal ID Print ISSN Online ISSN                      Original Title  \\\n",
       "0      486254  1989-3477         NaN  @tic.revista d'innovació educativa   \n",
       "\n",
       "                  International Title Country of Publication  \\\n",
       "0  @tic.revista d'innovació educativa                  Spain   \n",
       "\n",
       "                               ERIH PLUS Disciplines  \\\n",
       "0  Interdisciplinary research in the Social Scien...   \n",
       "\n",
       "                          OECD Classifications       [Last Updated]  \n",
       "0  Educational Sciences; Other Social Sciences  2015-06-25 13:48:26  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erih_plus_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_meta_csv(file_path, erih_plus_df):\n",
    "    meta_data = pd.read_csv(file_path)\n",
    "    meta_data['venue'] = meta_data['venue'].astype(str)\n",
    "    meta_data['issn'] = meta_data['venue'].str.extract(r'issn:(\\d{4}-\\d{3}[\\dX])')\n",
    "    \n",
    "    # Extract the identifier (OMID) from the 'id' column\n",
    "    meta_data['id'] = meta_data['id'].str.extract(r'(meta:[^ ]*)')\n",
    "    \n",
    "    merged_data_print = erih_plus_df.merge(meta_data, left_on='Print ISSN', right_on='issn', how='inner')\n",
    "    merged_data_online = erih_plus_df.merge(meta_data, left_on='Online ISSN', right_on='issn', how='inner')\n",
    "    merged_data = pd.concat([merged_data_print, merged_data_online], ignore_index=True)\n",
    "    \n",
    "    # Keep only the relevant columns for the mapping dataframe\n",
    "    merged_data = merged_data[['id', 'issn', 'Journal ID', 'Print ISSN', 'Online ISSN']].rename(columns={'id': 'OC_OMID', 'issn': 'OC_ISSN', 'Journal ID': 'EP_ID', 'Print ISSN': 'EP_Print_ISSN', 'Online ISSN': 'EP_Online_ISSN'})\n",
    "    \n",
    "    # Create the 'EP_ISSN' column\n",
    "    merged_data['EP_ISSN'] = merged_data['EP_Print_ISSN'].combine_first(merged_data['EP_Online_ISSN'])\n",
    "    \n",
    "    # Drop the 'EP_Print_ISSN' and 'EP_Online_ISSN' columns\n",
    "    merged_data = merged_data.drop(columns=['EP_Print_ISSN', 'EP_Online_ISSN'])\n",
    "    \n",
    "    # Drop rows with NaN values in the 'OC_ISSN' column\n",
    "    merged_data = merged_data.dropna(subset=['OC_ISSN']).reset_index(drop=True)\n",
    "\n",
    "    return merged_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_file(input_file, erih_plus_df):\n",
    "    chunksize = 3 * 10 ** 3\n",
    "    processed_chunks = []\n",
    "    \n",
    "    # Read the input_file in chunks and process each chunk\n",
    "    with pd.read_csv(input_file, chunksize=chunksize) as reader:\n",
    "        for chunk in reader:\n",
    "            processed_chunk = process_meta_csv(chunk, erih_plus_df)\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "    # Combine the processed chunks into a single DataFrame\n",
    "    return pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "input_directory = \"I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump\"\n",
    "files = glob.glob(os.path.join(input_directory, \"*.csv\"))\n",
    "\n",
    "# Number of files to process at once\n",
    "batch_size = 10\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Initialize a progress bar to visualize the progress of processing batches of files\n",
    "with tqdm(total=len(files), desc=\"Batches\") as pbar:\n",
    "    # Process files in batches\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        # Get the current batch of files\n",
    "        batch_files = files[i:i + batch_size]\n",
    "\n",
    "        # Process the current batch of files using a ProcessPoolExecutor for parallelism\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            results = executor.map(process_file, batch_files, [erih_plus_df] * len(batch_files))\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        # Update the progress bar for each batch\n",
    "        pbar.update(len(batch_files))\n",
    "\n",
    "# Combine the results from all batches into a single DataFrame\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_file(input_file, erih_plus_df):\n",
    "    chunksize = 3 * 10 ** 3\n",
    "    processed_chunks = []\n",
    "    \n",
    "    with pd.read_csv(input_file, chunksize=chunksize) as reader:\n",
    "        for chunk in reader:\n",
    "            processed_chunk = process_meta_csv(chunk, erih_plus_df)\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "    return pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "input_directory = \"I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump\"\n",
    "files = glob.glob(os.path.join(input_directory, \"*.csv\"))\n",
    "\n",
    "# Number of files to process at once\n",
    "batch_size = 10\n",
    "\n",
    "all_results = []\n",
    "\n",
    "with tqdm(total=len(files), desc=\"Batches\") as pbar:\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i + batch_size]\n",
    "\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            results = executor.map(process_file, batch_files, [erih_plus_df] * len(batch_files))\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        # Update the progress bar for each batch\n",
    "        pbar.update(len(batch_files))\n",
    "\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "def process_file(input_file, erih_plus_df):\n",
    "    chunksize = 3 * 10 ** 3\n",
    "    processed_chunks = []\n",
    "\n",
    "    with pd.read_csv(input_file, chunksize=chunksize) as reader:\n",
    "        for chunk in reader:\n",
    "            processed_chunk = process_meta_csv(chunk, erih_plus_df)\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "    return pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "input_directory = \"I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump\"\n",
    "files = glob.glob(os.path.join(input_directory, \"*.csv\"))\n",
    "\n",
    "# Number of files to process at once\n",
    "batch_size = 10\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i in range(0, len(files), batch_size):\n",
    "    batch_files = files[i:i + batch_size]\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(process_file, batch_files, [erih_plus_df] * len(batch_files))\n",
    "        all_results.extend(results)\n",
    "\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def process_meta_csv_wrapper(args):\n",
    "    return process_meta_csv(*args)\n",
    "\n",
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump'\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "batch_size = 100\n",
    "num_batches = len(csv_files) // batch_size + (1 if len(csv_files) % batch_size > 0 else 0)\n",
    "\n",
    "temp_files = []\n",
    "\n",
    "with tqdm(total=len(csv_files)) as pbar:\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(csv_files))\n",
    "        batch_files = csv_files[start_idx:end_idx]\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            results = list(executor.map(process_meta_csv_wrapper, [(file, erih_plus_df) for file in batch_files]))\n",
    "\n",
    "        batch_data = pd.concat(results, ignore_index=True)\n",
    "        temp_file = f\"temp_merged_data_{batch_idx}.csv\"\n",
    "        batch_data.to_csv(temp_file, index=False)\n",
    "        temp_files.append(temp_file)\n",
    "\n",
    "        # Update progress bar for each file in the batch\n",
    "        pbar.update(len(batch_files))\n",
    "\n",
    "# Load temporary files and concatenate them\n",
    "merged_data = pd.concat([pd.read_csv(temp_file) for temp_file in temp_files], ignore_index=True)\n",
    "\n",
    "# Remove temporary files\n",
    "for temp_file in temp_files:\n",
    "    os.remove(temp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def process_meta_csv_wrapper(args):\n",
    "    return process_meta_csv(*args)\n",
    "\n",
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump'\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "batch_size = 100\n",
    "num_batches = len(csv_files) // batch_size + (1 if len(csv_files) % batch_size > 0 else 0)\n",
    "\n",
    "temp_files = []\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(csv_files))\n",
    "    batch_files = csv_files[start_idx:end_idx]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = list(tqdm(executor.map(process_meta_csv_wrapper, [(file, erih_plus_df) for file in batch_files]), total=len(batch_files)))\n",
    "\n",
    "    batch_data = pd.concat(results, ignore_index=True)\n",
    "    temp_file = f\"temp_merged_data_{batch_idx}.csv\"\n",
    "    batch_data.to_csv(temp_file, index=False)\n",
    "    temp_files.append(temp_file)\n",
    "\n",
    "# Load temporary files and concatenate them\n",
    "merged_data = pd.concat([pd.read_csv(temp_file) for temp_file in temp_files], ignore_index=True)\n",
    "\n",
    "# Remove temporary files\n",
    "for temp_file in temp_files:\n",
    "    os.remove(temp_file) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\solo_one'\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(csv_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, file_name)\n",
    "        merged_data_file = process_meta_csv(file_path, erih_plus_df)\n",
    "        merged_data = pd.concat([merged_data, merged_data_file], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OC_OMID</th>\n",
       "      <th>OC_ISSN</th>\n",
       "      <th>EP_ID</th>\n",
       "      <th>EP_ISSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta:br/0601646</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           OC_OMID    OC_ISSN   EP_ID    EP_ISSN\n",
       "0  meta:br/0601646  0172-6404  471777  0172-6404"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OC_OMID</th>\n",
       "      <th>OC_ISSN</th>\n",
       "      <th>EP_ID</th>\n",
       "      <th>EP_ISSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta:br/0601646</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta:br/0601638</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta:br/0601645</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta:br/0601643</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta:br/0601640</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta:br/0601642</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta:br/0601644</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta:br/0601648</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta:br/0601647</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta:br/0601637</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta:br/0601639</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta:br/0601641</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OC_OMID    OC_ISSN   EP_ID    EP_ISSN\n",
       "0   meta:br/0601646  0172-6404  471777  0172-6404\n",
       "1   meta:br/0601638  0172-6404  471777  0172-6404\n",
       "2   meta:br/0601645  0172-6404  471777  0172-6404\n",
       "3   meta:br/0601643  0172-6404  471777  0172-6404\n",
       "4   meta:br/0601640  0172-6404  471777  0172-6404\n",
       "5   meta:br/0601642  0172-6404  471777  0172-6404\n",
       "6   meta:br/0601644  0172-6404  471777  0172-6404\n",
       "7   meta:br/0601648  0172-6404  471777  0172-6404\n",
       "8   meta:br/0601647  0172-6404  471777  0172-6404\n",
       "9   meta:br/0601637  0172-6404  471777  0172-6404\n",
       "10  meta:br/0601639  0172-6404  471777  0172-6404\n",
       "11  meta:br/0601641  0172-6404  471777  0172-6404"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" new_merged_data = merged_data.dropna(subset=['OC_ISSN']).reset_index(drop=True)\\nnew_merged_data.head(2) \""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" new_merged_data = merged_data.dropna(subset=['OC_ISSN']).reset_index(drop=True)\n",
    "new_merged_data.head(2) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "\n",
    "HERE WE NEED TO HAVE A STEP FOR ADDING INFORMATION ABOUT OPEN ACCESS TO THE DATAFRAME WE JUST CREATED, SO THAT THE OMIDS ARE DIRECTLY CONNECTED TO THE INFORMATION ABOUT ACCESSIBILITY OF THE JOURNAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DOAJ CSV file into a DataFrame\n",
    "doaj_file_path = 'journalcsv__doaj.csv'\n",
    "doaj_df = pd.read_csv(doaj_file_path, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19278 entries, 0 to 19277\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                                                       Non-Null Count  Dtype  \n",
      "---  ------                                                                       --------------  -----  \n",
      " 0   Journal title                                                                19278 non-null  object \n",
      " 1   Journal URL                                                                  19278 non-null  object \n",
      " 2   URL in DOAJ                                                                  19278 non-null  object \n",
      " 3   When did the journal start to publish all content using an open license?     19277 non-null  float64\n",
      " 4   Alternative title                                                            7485 non-null   object \n",
      " 5   Journal ISSN (print version)                                                 11148 non-null  object \n",
      " 6   Journal EISSN (online version)                                               18315 non-null  object \n",
      " 7   Keywords                                                                     19278 non-null  object \n",
      " 8   Languages in which the journal accepts manuscripts                           19278 non-null  object \n",
      " 9   Publisher                                                                    19277 non-null  object \n",
      " 10  Country of publisher                                                         19278 non-null  object \n",
      " 11  Society or institution                                                       10277 non-null  object \n",
      " 12  Country of society or institution                                            3351 non-null   object \n",
      " 13  Journal license                                                              19278 non-null  object \n",
      " 14  License attributes                                                           255 non-null    object \n",
      " 15  URL for license terms                                                        19248 non-null  object \n",
      " 16  Machine-readable CC licensing information embedded or displayed in articles  10331 non-null  object \n",
      " 17  URL to an example page with embedded licensing information                   10427 non-null  object \n",
      " 18  Author holds copyright without restrictions                                  19278 non-null  object \n",
      " 19  Copyright information URL                                                    14663 non-null  object \n",
      " 20  Review process                                                               19278 non-null  object \n",
      " 21  Review process information URL                                               19278 non-null  object \n",
      " 22  Journal plagiarism screening policy                                          19278 non-null  object \n",
      " 23  Plagiarism information URL                                                   11350 non-null  object \n",
      " 24  URL for journal's aims & scope                                               19278 non-null  object \n",
      " 25  URL for the Editorial Board page                                             19278 non-null  object \n",
      " 26  URL for journal's instructions for authors                                   19278 non-null  object \n",
      " 27  Average number of weeks between article submission and publication           19278 non-null  int64  \n",
      " 28  APC                                                                          19278 non-null  object \n",
      " 29  APC information URL                                                          19259 non-null  object \n",
      " 30  APC amount                                                                   6190 non-null   object \n",
      " 31  Journal waiver policy (for developing country authors etc)                   19278 non-null  object \n",
      " 32  Waiver policy information URL                                                4275 non-null   object \n",
      " 33  Has other fees                                                               19278 non-null  object \n",
      " 34  Other fees information URL                                                   8581 non-null   object \n",
      " 35  Preservation Services                                                        6590 non-null   object \n",
      " 36  Preservation Service: national library                                       2751 non-null   object \n",
      " 37  Preservation information URL                                                 9788 non-null   object \n",
      " 38  Deposit policy directory                                                     6605 non-null   object \n",
      " 39  URL for deposit policy                                                       3498 non-null   object \n",
      " 40  Persistent article identifiers                                               14486 non-null  object \n",
      " 41  Article metadata includes ORCIDs                                             9394 non-null   object \n",
      " 42  Journal complies with I4OC standards for open citations                      9395 non-null   object \n",
      " 43  Does the journal comply to DOAJ's definition of open access?                 19263 non-null  object \n",
      " 44  URL for journal's Open Access statement                                      19278 non-null  object \n",
      " 45  Continues                                                                    347 non-null    object \n",
      " 46  Continued By                                                                 243 non-null    object \n",
      " 47  LCC Codes                                                                    19278 non-null  object \n",
      " 48  Subjects                                                                     19278 non-null  object \n",
      " 49  DOAJ Seal                                                                    19278 non-null  object \n",
      " 50  Added on Date                                                                19278 non-null  object \n",
      " 51  Last updated Date                                                            19278 non-null  object \n",
      " 52  Number of Article Records                                                    19278 non-null  int64  \n",
      " 53  Most Recent Article Added                                                    15857 non-null  object \n",
      "dtypes: float64(1), int64(2), object(51)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "doaj_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Journal ISSN (print version)', 'Journal EISSN (online version)',\n",
       "       'Country of publisher'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doaj = doaj_df.iloc[1:, [5, 6, 10]]\n",
    "new_doaj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of Open Access ISSNs\n",
    "open_access_dict = {}\n",
    "\n",
    "for index, row in new_doaj.iterrows():\n",
    "    open_access_dict[row['Journal ISSN (print version)']] = True\n",
    "    open_access_dict[row['Journal EISSN (online version)']] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Open Access information with the main dataframe\n",
    "#new_merged_data['Open Access'] = new_merged_data['OC_ISSN'].map(open_access_dict)\n",
    "merged_data['Open Access'] = merged_data['OC_ISSN'].map(open_access_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Open Access information with 'Unknown'\n",
    "#new_merged_data['Open Access'] = new_merged_data['Open Access'].fillna('Unknown')\n",
    "merged_data['Open Access'] = merged_data['Open Access'].fillna('Unknown')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OC_OMID</th>\n",
       "      <th>OC_ISSN</th>\n",
       "      <th>EP_ID</th>\n",
       "      <th>EP_ISSN</th>\n",
       "      <th>Open Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta:br/0601646</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta:br/0601638</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta:br/0601645</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta:br/0601643</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta:br/0601640</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta:br/0601642</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta:br/0601644</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta:br/0601648</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta:br/0601647</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta:br/0601637</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta:br/0601639</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta:br/0601641</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>471777</td>\n",
       "      <td>0172-6404</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OC_OMID    OC_ISSN   EP_ID    EP_ISSN Open Access\n",
       "0   meta:br/0601646  0172-6404  471777  0172-6404     Unknown\n",
       "1   meta:br/0601638  0172-6404  471777  0172-6404     Unknown\n",
       "2   meta:br/0601645  0172-6404  471777  0172-6404     Unknown\n",
       "3   meta:br/0601643  0172-6404  471777  0172-6404     Unknown\n",
       "4   meta:br/0601640  0172-6404  471777  0172-6404     Unknown\n",
       "5   meta:br/0601642  0172-6404  471777  0172-6404     Unknown\n",
       "6   meta:br/0601644  0172-6404  471777  0172-6404     Unknown\n",
       "7   meta:br/0601648  0172-6404  471777  0172-6404     Unknown\n",
       "8   meta:br/0601647  0172-6404  471777  0172-6404     Unknown\n",
       "9   meta:br/0601637  0172-6404  471777  0172-6404     Unknown\n",
       "10  meta:br/0601639  0172-6404  471777  0172-6404     Unknown\n",
       "11  meta:br/0601641  0172-6404  471777  0172-6404     Unknown"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_merged_data.head()\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique ISSNs found in 5 files: 54\n",
      "Sample ISSNs: ['2222-1751', '1736-8723', '1738-1266', '0098-7921', '0198-8220', '1229-5949', '1806-3756', '1662-9779', '0753-3322', '1765-2952']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_directory = 'I:\\\\open-sci\\\\dump-files\\\\opencitations-meta\\\\partial_dump'\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "# Select the first 5 CSV files to check\n",
    "files_to_check = csv_files[:5]\n",
    "\n",
    "# Initialize a set to store unique ISSNs\n",
    "unique_issns = set()\n",
    "\n",
    "for file in files_to_check:\n",
    "    df = pd.read_csv(file)\n",
    "    df['venue'] = df['venue'].astype(str)\n",
    "    df['issn'] = df['venue'].str.extract(r'issn:(\\d{4}-\\d{3}[\\dX])')\n",
    "    unique_issns.update(df['issn'].dropna().tolist())\n",
    "\n",
    "print(f\"Total unique ISSNs found in {len(files_to_check)} files: {len(unique_issns)}\")\n",
    "print(\"Sample ISSNs:\", list(unique_issns)[:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
